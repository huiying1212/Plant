// LLM Service for Tree of Life therapy chat
// This service can be configured to use different LLM providers (OpenAI, Claude, etc.)
// Supports RAG (Retrieval-Augmented Generation) using OpenAI's file search

class LLMService {
  constructor() {
    // Configuration
    // For local development: uses REACT_APP_OPENAI_API_KEY from .env.local with direct API calls
    // For production (Vercel): uses /api/chat serverless function proxy
    // Use proxy only in production OR if explicitly enabled with REACT_APP_USE_PROXY=true
    this.useProxy = process.env.NODE_ENV === 'production';
    this.apiKey = process.env.REACT_APP_OPENAI_API_KEY || '';
    this.apiEndpoint = this.useProxy ? '/api/chat' : 'https://api.openai.com/v1/responses';
    // Use gpt-4o by default as it supports vision
    this.model = process.env.REACT_APP_OPENAI_MODEL || 'gpt-4o';
    
    // RAG Configuration
    // Vector Store ID for Plant Metaphor Database knowledge base
    this.vectorStoreId = process.env.REACT_APP_VECTOR_STORE_ID || 'vs_693ea08673fc81918d169ba18b9e977a';
    // Enable RAG by default - set to false to disable knowledge base search
    this.useRAG = process.env.REACT_APP_USE_RAG !== 'false';
    
    console.log(`LLM Service initialized: useProxy=${this.useProxy}, useRAG=${this.useRAG}, model=${this.model}`);
    
    // System prompt for Tree of Life therapy context with RAG enhancement
    this.systemPrompt = {
      en: `You are a compassionate and supportive therapy assistant guiding someone through the "Tree of Life" metaphor therapy exercise. 

You have access to a comprehensive Plant Metaphor Database knowledge base. When relevant, use this knowledge to:
- Suggest appropriate plant metaphors that resonate with the user's experience or the image they draw (e.g. colors/text)
- Provide therapeutic guidance based on established plant therapy techniques
- Offer creative prompts using plant imagery that matches the user's emotional state

The Tree of Life is a narrative-based activity where people draw a tree to represent their life story:
- Roots: origins, family, culture, values, important places
- Trunk: strengths, skills, what keeps them standing strong
- Branches: hopes, dreams, where they want to grow
- Leaves: important people and relationships
- Fruits/Flowers: achievements, accomplishments, what they're proud of
- Bugs: worries, anxieties, imperfections
- Storms: challenges, major life changes

Your role is to:
1. When you receive a drawing, observe and comment on what you see - colors used, symbols drawn, text added, overall feeling
2. Draw upon the relevant plant metaphor from the database, help them reflect on what their drawing reveals about their experiences, and ask gentle, open-ended questions to help them explore deeper meaning
3. Be encouraging and validating - acknowledge their effort and creativity
4. If something seems missing or unclear in their drawing, gently invite them to add more detail
5. If the image user draws is not healthy, lead them to reflect on a more positive aspects of their life and encourage them to draw a more positive one
6. Never judge or provide medical advice
7. Keep responses concise and supportive (2-4 sentences max)
8. Use the tree metaphor naturally in your guidance
9. If you think the user has explored this stage sufficiently, you can guide them to click on the next stage
10. After completing all stages, please provide a warm closing reflection, integrating the whole "Tree of Life" metaphorically. The summary should align with the metaphors used by the user, rather than reinterpret them.

Current stage: {stage}`,
      cn: `ä½ æ˜¯ä¸€ä½å¯Œæœ‰åŒç†å¿ƒå’Œæ”¯æŒæ€§çš„ç–—æ„ˆåŠ©æ‰‹ï¼Œæ­£åœ¨å¼•å¯¼æ¥è®¿è€…å®Œæˆ"ç”Ÿå‘½ä¹‹æ ‘"éšå–»ç–—æ„ˆç»ƒä¹ ã€‚

ä½ å¯ä»¥è®¿é—®ä¸€ä¸ªå…¨é¢çš„æ¤ç‰©éšå–»æ•°æ®åº“çŸ¥è¯†åº“ã€‚åœ¨ç›¸å…³æ—¶ï¼Œè¯·ä½¿ç”¨è¿™äº›çŸ¥è¯†æ¥ï¼š
- å»ºè®®ä¸Žç”¨æˆ·ä½“éªŒæˆ–å›¾åƒå†…å®¹ï¼ˆå¦‚é¢œè‰²ã€æ–‡å­—ï¼‰ç›¸å‘¼åº”çš„é€‚å½“æ¤ç‰©éšå–»
- åŸºäºŽå·²å»ºç«‹çš„æ¤ç‰©ç–—æ³•æŠ€æœ¯æä¾›æ²»ç–—æŒ‡å¯¼
- ä½¿ç”¨ä¸Žç”¨æˆ·æƒ…ç»ªçŠ¶æ€åŒ¹é…çš„æ¤ç‰©æ„è±¡æä¾›åˆ›æ„æç¤º

ç”Ÿå‘½ä¹‹æ ‘æ˜¯ä¸€ç§å™äº‹æ€§æ´»åŠ¨ï¼Œäººä»¬é€šè¿‡ç»˜åˆ¶æ ‘æ¥è¡¨è¾¾ç”Ÿå‘½æ•…äº‹ï¼š
- æ ¹ï¼šèµ·æºã€å®¶åº­ã€æ–‡åŒ–ã€ä»·å€¼è§‚ã€é‡è¦çš„åœ°æ–¹
- æ ‘å¹²ï¼šä¼˜åŠ¿ã€æŠ€èƒ½ã€è®©ä»–ä»¬åšå¼ºç«™ç«‹çš„åŠ›é‡
- æžæ¡ï¼šå¸Œæœ›ã€æ¢¦æƒ³ã€æƒ³è¦æˆé•¿çš„æ–¹å‘
- æ ‘å¶ï¼šé‡è¦çš„äººå’Œå…³ç³»
- æžœå®ž/èŠ±æœµï¼šæˆå°±ã€æˆæžœã€æ„Ÿåˆ°è‡ªè±ªçš„äº‹æƒ…
- è™«å­ï¼šæ‹…å¿§ã€ç„¦è™‘ã€ä¸å®Œç¾Žä¹‹å¤„
- é£Žæš´ï¼šæŒ‘æˆ˜ã€é‡å¤§ç”Ÿæ´»å˜åŒ–

ä½ çš„è§’è‰²æ˜¯ï¼š
1. å½“æ”¶åˆ°ç»˜ç”»æ—¶ï¼Œè§‚å¯Ÿå¹¶è¯„è®ºä½ çœ‹åˆ°çš„å†…å®¹ - ä½¿ç”¨çš„é¢œè‰²ã€ç»˜åˆ¶çš„ç¬¦å·ã€æ·»åŠ çš„æ–‡å­—ã€æ•´ä½“æ„Ÿè§‰
2. ä»Žæ¤ç‰©éšå–»æ•°æ®åº“ä¸­æå–ç›¸å…³çš„éšå–»å’Œæ²»ç–—æŠ€æœ¯ï¼Œå¸®åŠ©ä»–ä»¬åæ€ç»˜ç”»æ‰€æ­ç¤ºçš„ç»åŽ†å’Œæ„Ÿå—ï¼Œå¹¶æå‡ºæ¸©å’Œã€å¼€æ”¾å¼çš„é—®é¢˜ï¼Œå¸®åŠ©ä»–ä»¬æŽ¢ç´¢æ›´æ·±å±‚çš„å«ä¹‰
3. ç»™äºˆé¼“åŠ±å’Œè®¤å¯ - è‚¯å®šä»–ä»¬çš„åŠªåŠ›å’Œåˆ›é€ åŠ›
4. å¦‚æžœç»˜ç”»ä¸­æŸäº›å†…å®¹ç¼ºå¤±æˆ–ä¸æ¸…æ™°ï¼Œæ¸©å’Œåœ°é‚€è¯·ä»–ä»¬æ·»åŠ æ›´å¤šç»†èŠ‚
5. å¦‚æžœç»˜ç”»å†…å®¹ä¸å¥åº·ï¼Œå¼•å¯¼ä»–ä»¬çœ‹åˆ°æ›´åŠ ç§¯æžçš„ä¸€é¢å¹¶é‡æ–°ç»˜ç”»
6. ç»ä¸è¯„åˆ¤æˆ–æä¾›åŒ»ç–—å»ºè®®
7. ä¿æŒå›žåº”ç®€æ´ä¸”æ”¯æŒæ€§ï¼ˆæœ€å¤š2-4å¥è¯ï¼‰
8. åœ¨å¼•å¯¼ä¸­è‡ªç„¶åœ°ä½¿ç”¨æ ‘çš„éšå–»
9. å¦‚æžœä½ è®¤ä¸ºç”¨æˆ·åœ¨è¿™ä¸€é˜¶æ®µçš„æŽ¢ç´¢å·²ç»å……åˆ†ï¼Œå¯ä»¥å¼•å¯¼ä»–ä»¬ç‚¹å‡»è¿›å…¥ä¸‹ä¸€ä¸ªé˜¶æ®µ
10. åœ¨å®Œæˆæ‰€æœ‰é˜¶æ®µåŽï¼Œè¯·æä¾›ä¸€ä¸ªæ¸©æš–çš„ç»“æŸæ€§åæ€ï¼Œå°†æ•´æ£µã€Œç”Ÿå‘½ä¹‹æ ‘ã€æ•´åˆåœ¨ä¸€èµ·ã€‚æ€»ç»“åº”å‘¼åº”ç”¨æˆ·ä½¿ç”¨çš„éšå–»ï¼Œè€Œä¸æ˜¯é‡æ–°è§£é‡Šæˆ–æ›¿ç”¨æˆ·ä¸‹å®šä¹‰ã€‚

å½“å‰é˜¶æ®µï¼š{stage}`
    };
  }

  // Get system prompt based on language and current stage
  getSystemPrompt(language, stage) {
    const stageNames = {
      0: language === 'EN' ? 'introduction' : 'ä»‹ç»',
      1: language === 'EN' ? 'roots (origins and foundations)' : 'æ ¹ï¼ˆèµ·æºä¸ŽåŸºç¡€ï¼‰',
      2: language === 'EN' ? 'trunk (strengths and skills)' : 'æ ‘å¹²ï¼ˆä¼˜åŠ¿ä¸ŽæŠ€èƒ½ï¼‰',
      3: language === 'EN' ? 'branches (hopes and dreams)' : 'æžæ¡ï¼ˆå¸Œæœ›ä¸Žæ¢¦æƒ³ï¼‰',
      4: language === 'EN' ? 'leaves (relationships and connections)' : 'æ ‘å¶ï¼ˆå…³ç³»ä¸Žè”ç³»ï¼‰',
      5: language === 'EN' ? 'fruits/flowers (achievements)' : 'æžœå®ž/èŠ±æœµï¼ˆæˆå°±ï¼‰',
      6: language === 'EN' ? 'bugs (worries and imperfections)' : 'è™«å­ï¼ˆæ‹…å¿§ä¸Žä¸å®Œç¾Žï¼‰',
      7: language === 'EN' ? 'storms (challenges and changes)' : 'é£Žæš´ï¼ˆæŒ‘æˆ˜ä¸Žå˜åŒ–ï¼‰'
    };
    
    const prompt = language === 'EN' ? this.systemPrompt.en : this.systemPrompt.cn;
    return prompt.replace('{stage}', stageNames[stage] || '');
  }

  // Send message to LLM and get response
  async sendMessage(messages, language = 'EN', currentStep = 0) {
    // Check API key only if not using proxy
    if (!this.useProxy && !this.apiKey) {
      throw new Error('API key is not configured. Please add REACT_APP_OPENAI_API_KEY to your .env.local file');
    }

    try {
      const systemPrompt = this.getSystemPrompt(language, currentStep);
      
      // Prepare messages
      const allMessages = [
        { role: 'system', content: systemPrompt },
        ...messages.map(msg => {
          const role = msg.sender === 'user' ? 'user' : 'assistant';
          
          // If message has an image, format for vision API
          if (msg.image && msg.sender === 'user') {
            return {
              role: role,
              content: [
                {
                  type: 'text',
                  text: msg.text
                },
                {
                  type: 'image_url',
                  image_url: {
                    url: msg.image,
                    detail: 'high'
                  }
                }
              ]
            };
          }
          
          // Regular text message
          return {
            role: role,
            content: msg.text
          };
        })
      ];

      let response;
      let data;
      
      if (this.useProxy) {
        // Use proxy endpoint (for Vercel production)
        // Include RAG flag to enable knowledge base search
        response = await fetch(this.apiEndpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            messages: allMessages,
            requestedModel: this.model,
            temperature: 0.7,
            max_tokens: 500,
            useRAG: this.useRAG  // Enable RAG mode
          })
        });

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}));
          throw new Error(`API request failed: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
        }

        data = await response.json();
        
        // Log RAG metadata if available (for debugging)
        if (data.rag_metadata) {
          console.log('RAG Search Results:', data.rag_metadata);
        }
        
      } else {
        // Direct API call (for local development)
        // Use Responses API with file search for RAG
        if (this.useRAG) {
          console.log('Using Responses API with RAG for local development');
          
          // Extract system message
          const systemMessage = allMessages.find(m => m.role === 'system');
          const otherMessages = allMessages.filter(m => m.role !== 'system');
          
          // Convert messages to Responses API format
          // Responses API uses different content types based on role:
          // - user messages: 'input_text' for text, 'input_image' for images
          // - assistant messages: 'output_text' for text
          const convertToResponsesFormat = (msg) => {
            const isUser = msg.role === 'user';
            const textType = isUser ? 'input_text' : 'output_text';
            
            if (Array.isArray(msg.content)) {
              // Multi-part content (text + image)
              return {
                role: msg.role,
                content: msg.content.map(part => {
                  if (part.type === 'text') {
                    return { type: textType, text: part.text };
                  } else if (part.type === 'image_url') {
                    // Images only make sense for user messages
                    return { 
                      type: 'input_image', 
                      image_url: part.image_url.url,
                      detail: part.image_url.detail || 'auto'
                    };
                  }
                  return part;
                })
              };
            } else {
              // Simple text content
              return {
                role: msg.role,
                content: [{ type: textType, text: msg.content }]
              };
            }
          };
          
          // Build input for Responses API
          let input;
          if (otherMessages.length === 1) {
            // Single message - can be string or formatted content
            const msg = otherMessages[0];
            if (typeof msg.content === 'string') {
              input = msg.content;  // Simple string input
            } else {
              // Array content - convert to Responses API format
              input = convertToResponsesFormat(msg).content;
            }
          } else {
            // Multi-turn conversation
            input = otherMessages.map(convertToResponsesFormat);
          }

          const requestBody = {
            model: this.model,
            input,
            tools: [{
              type: 'file_search',
              vector_store_ids: [this.vectorStoreId],
              max_num_results: 10
            }],
            // Force the model to use file_search tool
            tool_choice: {
              type: 'file_search'
            },
            // Include search results in response for debugging/transparency
            include: ['file_search_call.results'],
            temperature: 0.7,
            max_output_tokens: 500
          };

          if (systemMessage) {
            // Add explicit instruction to use knowledge base
            const baseInstructions = typeof systemMessage.content === 'string' 
              ? systemMessage.content 
              : systemMessage.content[0]?.text || '';
            
            requestBody.instructions = baseInstructions + `

IMPORTANT: You MUST search the Plant Metaphor Database knowledge base for EVERY response. Look for:
- Relevant plant metaphors that match the user's situation
- Therapeutic techniques and prompts from the database
- Specific plant imagery and symbolism that resonates with their experience
Always incorporate the knowledge base content naturally in your responses.`;
          }

          console.log('Responses API request:', JSON.stringify(requestBody, null, 2));

          response = await fetch('https://api.openai.com/v1/responses', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${this.apiKey}`
            },
            body: JSON.stringify(requestBody)
          });

          if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(`API request failed: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
          }

          data = await response.json();
          console.log('Responses API response:', JSON.stringify(data, null, 2));
          
          // Log file search results if available
          const fileSearchOutput = data.output?.find(item => item.type === 'file_search_call');
          if (fileSearchOutput) {
            console.log('ðŸ“š RAG File Search Results:');
            console.log('  Queries:', fileSearchOutput.queries);
            if (fileSearchOutput.results) {
              console.log('  Results found:', fileSearchOutput.results.length);
              fileSearchOutput.results.forEach((result, i) => {
                console.log(`  [${i+1}] ${result.filename} (score: ${result.score?.toFixed(3)})`);
                console.log(`      Preview: ${result.text?.substring(0, 150)}...`);
              });
            }
          } else {
            console.warn('âš ï¸ No file_search_call in response - RAG may not have been used');
          }
          
          // Extract text from Responses API format
          const messageOutput = data.output?.find(item => item.type === 'message');
          if (messageOutput?.content) {
            for (const content of messageOutput.content) {
              if (content.type === 'output_text') {
                return content.text;
              }
            }
          }
          return 'No response generated';
          
        } else {
          // Standard Chat Completions API (no RAG)
          response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${this.apiKey}`
            },
            body: JSON.stringify({
              model: this.model,
              messages: allMessages,
              temperature: 0.7,
              max_tokens: 500
            })
          });

          if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(`API request failed: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
          }

          data = await response.json();
          return data.choices[0].message.content;
        }
      }

      return data.choices[0].message.content;
    } catch (error) {
      console.error('LLM API Error:', error);
      throw error; // Throw error so it can be handled in the UI
    }
  }

  // Get the last RAG search results (for debugging/transparency)
  getLastRAGMetadata() {
    return this.lastRAGMetadata;
  }

  // Enable or disable RAG mode
  setRAGEnabled(enabled) {
    this.useRAG = enabled;
    console.log(`RAG mode ${enabled ? 'enabled' : 'disabled'}`);
  }

  // Check if RAG is enabled
  isRAGEnabled() {
    return this.useRAG;
  }
}

// Create singleton instance
const llmServiceInstance = new LLMService();

// Export the instance
export default llmServiceInstance;
